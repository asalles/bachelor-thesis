% Tomas Coufal xcoufa09@stud.fit.vutbr.cz
% Content of the Bachelor Thesis
%!TEX root = xcoufa09.tex

\chapter{Introduction}
\label{chap:Introduction}
In past few years the term of Cloud computing resonates worldwide and gains popularity. There have been plenty of papers and articles written about it and every large IT corporation interested in new market has brought their own solutions. Cloud computing has become well established business and ultimate answer for nearly every demand company can have these days. But when it comes to the meaning of these two words not everyone knows what exactly to expect. In a nutshell in means highly scalable and accessible platform available through network connection where the word platform stands for a huge variety of software: from virtual machines and specialized databases to applications like web office suites. In so called cloud whole internal corporate infrastructures are run along with customer facing products with ease. Rising complexity and competition between different cloud providers and types of services creates a demand for an easier management to provide more efficient yet reliable ways to provide the same level of control over the offered services.

By this thesis we slightly describe the main challenges that cloud managing tools are facing while integrating with providers offering various systems and subsytems with different capabilities. The described process is going to be based on an implemented \textbf{IBM SoftLayer} cloud service integration with open-source project \textbf{ManageIQ}. This work covers how to distinguish and differentiate the same functionality across naming conventions and service capabilities, how to integrate them into \textbf{ManageIQ} and how to establish working communication between \textbf{IBM SoftLayer} and the cloud manager. This thesis aims to simplify, sort out and sum up the knowledge needed to implement such integration for future \textbf{ManageIQ} provider integrators.

\section{Cloud computing}
\label{sec:Cloud computing}
Before we reveal the complexity of cloud computing and describe the challenges in managing cloud services across providers it is worth describing what the word \texttt{cloud} actually covers, what it means, why it is a need for huge variety of companies and how the IT industry invented such technologies~\cite{cervone}.

\subsection{Transition from traditional computing to the cloud}
\label{sub:Transition from traditional computing to the cloud}

In history the general approach how to implement a solid and reliable IT infrastructure changed several times. To understand well the thinking process behind this evolution let me shortly describe the needs and demands of the industry.

\subsubsection{Traditional way}
\label{subs:Traditional way}

The historically first and simplest approach for a company to implement and manage their own service in the Internet era is to use their own machines and servers. To lower the risks of a hardware failure this solution requires to mirror the application and it's data over multiple servers or even into a cluster of serves. This brings a lot of investments and requires a lot of maintenance on the company side.

Servers are considered as a base unit that encapsulates all the necessary hardware, operating systems, storage and any other utilities necessary. When the applications reaches limits of its dedicated server some additional hardware has to be provided. Despite the fact application can consume a lot of resources, it's not happening all the time. As an example you can think of a delivery or ordering system. During the year the amount of transactions are equal but before e.g. Christmas the peak in transactions can be high. Nevertheless the downside is once you have server configured to run one application that can use all its resources during the peak you can't use the resources left unused during the application idle. And when the system meats failure the recovery process is complicated. In the matter of scalability this approach is not functional enough.

\subsubsection{Virtualized computing}
\label{subs:Virtualized computing}

Because of all the disadvantages listed above new approach needs to be invented. To lower the complexity of hardware scaling IT industry moved towards an increase on software difficulty. Unlike hardware maintenance this can be automated easily and requires less resources to deploy. Servers are no more considered as atomic units. The fact that hardware itself can be abstract leads to an invention of \emph{virtualized computing}. The paradigm of virtualization brings virtual machine manager also known as \emph{hypervisor}, a specialized operating system designed to run multiple operating systems as applications. This manager provides the necessary layer that can encapsulate each environment. The isolation of hardware from operating systems makes it possible to run multiple services on one physical machine. Each virtual machine is provided by the resources it needs and when these are left unused hypervisor manages to pass them where is needed.

However when a physical failure appears the situation is the same. The service has to be moved to another device. What differs is the solution. Usually the hypervisors are run in clusters of physical servers where they can cooperate. When one hypervisor is facing a hardware failure the services are smoothly swapped to another physical device, under different hypervisor within the same cluster. This can happened without any outage of service and without the need for running a parallel fallback machine. This flexibility also helps the scalability mentioned above. In case of multiple services running on one physical device, the resources are assinged dynamically and once an application demands more the hypervisor can offer the less loaded virtual machines are transitioned to another server in cluster. This creates an environment where no virtual machines suffers from significant lack of resources.

\subsubsection{Outsourcing the virtualization}
\label{subs:Outsourcing the virtualization}

The core idea behind virtualization is the same for \emph{cloud computing} as well. A company using a virtualized solution typically owns the physical servers and maintains them on their own. This produces much overhead costs. On the other hand in cloud computing environment there is no need to insist on keeping the infrastructure. The operational responsibilities are shifted to the cloud provider who is responsible for the hardware and its maintenance. Providers offers remotely controlled virtual environment, location independent and highly scalable solution. The advantages of virtual computing sustain, applications are still run in virtual environment, scaled on demand and flexible. The creation of new virtual machines is a matter of minutes and no additional resources are needed.

Cloud computing providers usually implements a pay-as-you-go model where all costs are based on actual usage and new applications are purchased when needed. Advantage of this payment model becomes even mere significant when company has a lot of applications that needs to run in the same and transaction peaks are expected at the same period of time. The load balancing mechanisms cloud providers dispose with, and thanks to size of their clusters the availability of the application is guaranteed  and the actual costs are much lower compared to the situation when company has to provide all the hardware on their own. And when the peaks are over all the necessary additional resources can be reused by the cloud provider for other applications. To contrast this situation in virtual computing model these resources would be left unused on the company side. The shares resources idea in huge clusters is one of the strongest advantages of cloud computing.

\subsection{Cloud typology}
\label{sub:Cloud typology}

Among the advantages of Cloud computing not only the scalability has to be taken into account. There are plenty of fields where the cloud solution excels in. For example the \emph{National Institute of Standards and Technology} of the USA defines the Cloud computing by these five most essential characteristics~\cite{hu}:

\begin{enumerate}
	\item On-demand self-service
	\item Broad network access
	\item Resource pooling
	\item Rapid elasticity
	\item Measured service
\end{enumerate}

On-demand self-service stands for a possibility for consumers to provision a computing power (meant as server time, dedicated storage etc.) as needed and without the necessity to interact with the service provider in person by any mean. This allows the customer to avoid the risk of not being able to scale his appliances when there is any kind of outage in the preferred type of communication established between him and the provider.

Broad network access is a term used to describe availability over network via standard communication channels while not discriminating client devices by types or platforms. The term is mainly used in context of private clouds where this idea goes slightly against the security principles this type of cloud is designed for. The main reason to involve broad network access is to make the infrastructure available also for remote workers and via tablets and smartphones.

Resource pooling is a criteria considering dynamical assignment and reassignment of resources to different customers based on their demand in multi-tenant model of cloud service. These resources are location independent and customer is not in control neither has the knowledge over the location where exactly the resources are. Nevertheless the location can be revealed on higher level of abstraction, on country or data center scale.

Rapid elasticity presumes the resources are provisioned and released automatically. This actions are done in a short period of time and from the customer's view the capabilities available typically appear as unlimited and any amount of resources can be up-scaled at any time.

Measured service is a term used for automatic control over cloud clusters resources in order to monitor, analyze, control and optimize the usage. This mechanism provides additional transparency over the service for both the customer and also the provider.

Cloud solutions can have many shapes and forms in general. To distinguish and differentiate between common types of Cloud multiple points of view should be mentioned. One scale to be considered is the availability to purchase a different deployment models. There exist private and public clouds. Public cloud means the cloud infrastructure is widely accessible by anyone. No matter if organization or a person, anyone is able to use the service provided. As an example of this type of cloud service the Amazon's \emph{AWS EC2}, Red Hat's \emph{OpenShift} and \emph{OpenStack}, Microsoft's \emph{Azure} or \emph{Google Cloud Platform} can be mentioned. By using public cloud customers share the same infrastructure for their virtual machines with others. In contrary there is a second option available. These so called private clouds are strictly used by one customer only and they are based on a special contract between the cloud service provider and the customer. This provides better options to keep control over the operation of purchased infrastructure and more security advantages as well. Since there is no other user of the cloud it avoids the risk of any vulnerabilities in the isolation of each application running within the cloud.

The other option how to differentiate between available cloud solutions is by its level of abstraction, the service models. According to the service-oriented architecture cloud computing providers offer three main services. These are (in stacking order) \emph{Infrastructure as a service}, \emph{Platform as a service} and finally \emph{Software as a service}.

\subsubsection{Software as a service (SaaS)}
\label{subs:Software as a service (SaaS)}

The most advanced and complex level of abstraction in cloud computing. Software as a service usually provides a customer facing applications accessible on demand. The provider installs and operates an application software for the customer in their cloud. Typically SaaS is licensed on a subscription basis offering parametrized environment along with high availability insurance. Great examples of such kind of service are Salesforce.com and web office suites like \emph{Google Docs} or \emph{Microsoft Office 365}. The portfolio of services covered by SaaS is huge and wide way beyond imagination. From offering solutions for different kinds of analysis like social networks profiling tools and advertisement, over communication platforms including video, audio, mailing services etc.\ to mobile offices like as the ones mentioned above.

\subsubsection{Platform as a service (PaaS)}
\label{subs:Platform as a service (PaaS)}

By providing a PaaS customer gains an environment that allows him to develop and run his own applications without a need for building and maintaining a complex infrastructure. Such customer has access to a solid stable and reliable platform of his desire and focus solely on the application he develops and deploys. Described environment covers countless setups and frameworks with or without included database, continuous integration, etc. This approach brings advantages of rapid, easy and secure deployment along with other benefits of the cloud.

\subsubsection{Infrastructure as a service (IaaS)}
\label{subs:Infrastructure as a service (IaaS)}

Last but not least the most low-lever approach how to provide services via cloud is to provide base infrastructure. This reflects the need for customized setups which are trusted by customer. In this case the term of infrastructure stands for virtual machines or even bare metal ones. These are usually deployed based on images built by customer itself which allows to quickly scale over predefined setups.

\chapter{IBM Cloud}
\label{chap:IBM Cloud}

Among others the IBM company also offers their own cloud solution the so called \textbf{IBM Cloud}. It's not a standalone project it's a summary name for whole portfolio. It comprises of complementary yet independent platforms and tools covering an extensive amount of application and use-cases delivering customer adjustable setups and products. When the customer demands IaaS, \emph{IBM SoftLayer} is the product he's asking for. For platform-based requirements IBM offers a cloud service named \emph{Bluemix}. There is also a vast amount of SaaS solutions delivered by the company via their very own \emph{IBM cloud} market. Some of them based on the \emph{IBM Watson} intelligence some standalone. This complex tooling allows IBM to deliver in the cloud market environment.

\chapter{IBM SoftLayer}
\label{chap:IBM SoftLayer}

This IaaS cloud service provided by the IBM Company is one of the world's largest cloud services available on market. In order to integrate this provider of cloud infrastructure it's better to acknowledge and recognize the merit. Exploring and studying its parts and internal structure helps to understand the way to a successful integration. Then the second part of this chapter, the very next step is to identify and describe the ways how can the provider be accessed via APIs and cloud binding libraries, what are the benefits and drawbacks of each option available. Finally by comparing these approaches decide which one is the most suitable for our needs of integration into the \textbf{ManageIQ}.

\section{Components}
\label{sec:Components}

Before elaborating the bindings and APIs it is necessary to introduce and describe the main and most important ares of IaaS clouds with focus on the \textbf{IBM SoftLayer}. The most notable parts that are required to know are listed below. Each user deploying his machine in cloud needs to decide following:

\begin{itemize}
	\item Where to place the machine?
	\item How is the virtualization is encapsulated?
	\item What are the resources available for purchased instance?
	\item Which software, operating systems are run and how to preserve data?
	\item How are the machines connected one to another?
\end{itemize}

Understanding these topics is essential for a customer to be able to successfully deploy his appliance.

\subsection{Regions, Zones and Data centers}
\label{sub:Regions, Zones and Data centers}

One of them most important yet moving parts when setting up the cloud infrastructure is to distinguish where the appliance is physically run. This is important in a case when customer wants to mirror infrastructure around the globe to ensure the accessibility, reliability and swiftness is as good as it is possible and not dependent on its user geographical location and time. It's a factor that can easily avoid or at least reduce the connection issues caused by Internet service providers and exchange points outages. Since neither the customer nor cloud provider is responsible and in charge of the connectivity provided to users of the infrastructure, placing customers devices as close as possible to its user destination makes sense. This is what usually the \emph{Regions} are referring to. However in the cloud environment specification of the exact physical location does not make much sense. The approximate and relative location is sufficient and the most common way is to refer to a continent or a market. For example the \textbf{Google Compute Engine}~\cite{gce} specifies its regions as: \texttt{Central US}, \texttt{Eastern US}, \texttt{Western Europe}, etc.

On the other hand a complementary entity takes place within each region. These are called \emph{Zones} or \emph{Availability Zones}. Numerous zones are present in each \emph{Region}. They are independent each one on another. The reason is to ensure that in a case of outage, scheduled maintenance or any other kind of issue affecting a zone the others are left untouched and available. When one zone is failing the others in the same remain remain reliable and available.

By using and specifying proper \emph{Regions} and \emph{Availability Zones} the customer can assure and enhance reliability, reduce latency and build a robust system which is both as close as the customer needs and distributed around the world in the same time. Each cloud provider has a slightly different philosophy how they comprehend and implement these principles. Let's describe the two most common approaches.

As we already mentioned the \emph{Google Compute Engine} where the understanding of the area specifications is probably the most fitting the definition. There are \emph{Regions} which refers to a continent or a country where the data centers are placed. Also within each there are couple of \emph{Availability Zones}, usually 3 or 4 of them, and these are independent. As a next example the \textbf{Microsoft Azure} provider can be mentioned. Their understanding of this scheme is a bit different. They provide \emph{Regions} based solution only~\cite{azure}. These are specified in much greater detail then in the Google's case and there are more of them. This provider is substituting \emph{Zones} by making regions smaller so customer can easily target the user (by selecting not just the continent but even a specific country) and yet keep the backup in the closest region. As an example this is a sample how they are named and where they are placed in the \textbf{Azure} cloud provider: \texttt{Central US} in Iowa, \texttt{North Central US} placed in Illinois or \texttt{Japan West} set in Osaka. Just a reminder, the exact locations are not publicly available for clouds of \textbf{Google Compute Engine} type because it's not important.

Let's focus on how the schema of\emph{Regions} and \emph{Zones} works in the \textbf{IBM SoftLayer} cloud provider. Their model is quite similar to the \textbf{Microsoft Azure}. However they do not use the term of \emph{Region}. Instead the \emph{Data Center} term is used~\cite{softlayer_datacenters}. This term truly refer to an exact location (for each center exact city is told). As the product pages describe the locations where data centers are placed are for instance \texttt{Dallas 01}, \texttt{Dallas 09}, \texttt{Amsterdam 02}, \texttt{Washington, D.C. 01} or just \texttt{Paris}.

As you noticed, there might be some redundancy within a location. When this happens (there are multiple data centers in one city) each data center is numbered. So how does this fit in the scheme described above? For the purposes of this thesis and for successful integration into \textbf{ManageIQ} let's consider each data center as a separate \emph{Region}. This is a valid approach because when the user of \textbf{IBM SoftLayer} is provisioning a new appliance he needs to select the desired data center of deployment. That's the same situation when deploying into \textbf{Google Compute Engine} where the customer has to select the \emph{Region}. Another point of view is that when there are multiple data centers within one city (let's say in the same \emph{Region}) the situation recalls a state when the provider offers multiple \emph{Availabilty Zones} for the region:

\begin{enumerate}
	\item Such data centers are in the same \emph{Region}.
	\item Each one is independent on another.
\end{enumerate}

This view can bring us the idea the \textbf{IBM SoftLayer} provider is actually offering an \emph{Availability Zones} mixed with \emph{Regions} and calls them \emph{Data centers}. On the other hand as being said each data center is selectable. In other words it is possible to pick each of them and deploy the appliance there. But this view goes strictly against the presumed policy that zones are managed internally by the provider and the user is usually not able to select, specify which zone is being used for his device. And there's also another aspect why the comparison of zones and data centers within the same location is not a valid one. There's no internal connection (beside the name) how the data centers can be linked to the others in the same city. The missing relation (via API, network, etc.) is finally the reason why to model every data center as a separate \emph{Region}.

\subsection{Servers}
\label{sub:Servers}

Once the user figures out where he can run his appliances, it's worth discovering what is being provisioned and run. In the clouds of the \emph{IaaS} type it is usually a some kind of \emph{server}. Previously it's been mentioned~\ref{subs:Outsourcing the virtualization} that the most common type of device is a \emph{virtual server}. But this is not the only article available. For numerous security reasons some cloud providers brings the possibility to run such virtual server in three types of environment. \textbf{IBM SoftLayer} provides all of them.

\subsubsection{Shared hardware}
\label{subs:Shared hardware}

To run a \emph{virtual server} on a shared hardware is the cheaper variant. It is also suitable for most of the needs. While the customer does not demand any special treatment like enhanced security features or a specific type of hardware, this is the way to go. The provisioned virtual server is placed on a server within the data center and under a \emph{hypervisor}. This hypervisor manages also other appliances and does not differentiate who is the customer, owner of the virtual machine. Shared hawrdare means shared environment in a sense of a communal hypervisor and shared physical layer between users.

\subsubsection{Dedicated hardware}
\label{subs:Dedicated hardware}

The opposite option is to reserve a \emph{dedicated hardware}. It's more expensive on the other hand more secure too. By using a dedicated machine for appliances owned by one user only brings another layer how to secure the data. Also some providers can offer an option to let the user be responsible over the \emph{hypervisor} too. In addition with running appliances on dedicated hardware makes the customer in complete control over the leased infrastructure.

\subsubsection{Bare metal servers}
\label{subs:Bare metal servers}

There's also an option, offered only by a minority of companies, to use the cloud to provide so called \emph{bare metal servers}. This means a completely different approach than cloud is known for. While user wants to keep his data super secure and isolated yet in stable, reliable and affordable environment it's possible to order a specific physical rack and run the customer's server there. Basically this approach recalls a kind of server housing with benefits of the cloud.

\subsection{Flavors}
\label{sub:Flavors}

Once the customer knows where the virtual machine should be run and what kind of virtualization the deployed setup requires, it's worth choosing the hardware resources (no matter if virtual or physical). This specification involves aspects like the processor cores count and frequency, amount of memory available for the device or how data are being stored, if data are stored on a local hard drive or available via network, what type of hard drive it should be, how many of them are attached, what should be their capacity etc. All these aspects can be specified manually and in special cases they are. The more common work flow is to store the favorite setups as \emph{flavors}. Each cloud provider also offers some default ones. For example the Table~\ref{tab:IBM SoftLayer default flavors} below describes the default \emph{flavors} used in the \textbf{IBM SoftLayer} cloud.

\begin{table}[ht]
	\centering
	\caption{IBM SoftLayer default flavors}\label{tab:IBM SoftLayer default flavors}
	\begin{tabular}{llrrrr}
		\toprule
		Identifier & Name                 & CPU cores & Memory (RAM) & Hard drives (HDD)     \\
		\midrule
		m1.tiny    & Tiny Instance        & 1         & 1\,GB        & 1 $\times$ 25\,GB     \\
		m1.small   & Small Instance       & 2         & 2\,GB        & 1 $\times$ 100\,GB    \\
		m1.medium  & Medium Instance      & 4         & 4\,GB        & 1 $\times$ 500\,GB    \\
		m1.large   & Large Instance       & 8         & 8\,GB        & 1 $\times$ 750\,GB    \\
		m1.xlarge  & Extra Large Instance & 16        & 16\,GB       & 1 $\times$ 1\,000\,GB \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Images, templates and snapshots}
\label{sub:Images, templates and snapshots}

\emph{Images} are used in order to replicate a virtual server running in cloud, store setups or deploy preconfigured systems. Some cloud providers and managers use a term \emph{Template} instead. They can be created basically in two possible ways. The provider can produce some basic images with operating systems based on the default installation setups adjusted to reflect the cloud specific features, configurations, etc. Such images can provide also a preconfigured application setup or platforms. As being said these templates are usually prepared by the provider to facilitate initial setups for the customer. Of course user can deploy such images on his own too. But since this type of templates are containing a default configuration it's much convenient for the customer to be provided by them. There's also a second way how to create an image. There's a possibility to create a \emph{Snapshot} of running virtual machine. It is a pretty essential feature for each cloud to prepare a setup and save it as an template for backup and redeployment purposes. User usually wants to scale his infrastructure and distribute it around the world in different regions or providers. By producing snapshots of his running virtual machines or uploading his own preconfigured ones it's easy to preserve state, data and environment and deploy, copy the instance, elsewhere. These image and snapshots created by a customer can be flagged as private and available for his own use only. Or there's also a possibility to make such template publicly available for other users of the cloud.

\subsection{Networking}
\label{sub:Networking}

And finally the last of the remarkable areas of IaaS clouds --- networking of the appliances. While a customer is provisioning a virtual machine this machine is a part of a greater infrastructure. Inside this complex system its components need to be connected and linked with others. In order to achieve that clouds and virtualized computing brings mechanisms of \emph{virtual networks}. These networks are modeled to behave and to offer the same functionality as their physical equivalents. It depends on a cloud provided but basically there are couple of types of network infrastructure entities.

\subsubsection{Network port}
\label{subs:Network port}

Each virtual server is provided with network interfaces with its very own MAC address and etc. They are usually called \emph{Virtual LANs} or \emph{Metwork ports}. They point to the network interfaces of the virtual machine but they are also propagated outside to the managing API or system above. Thanks to this propagation they can be dynamically modified via API or the tooling provided by the cloud provider.

\subsubsection{Cloud networks and subents}
\label{subs:Cloud networks and subents}

Each port can be connected to a \emph{virtual cloud network} or a \emph{cloud subnet} while these networks works the same as in the world of regular computer networks. They are provided by a IP address ranges (so the device can receive a mapping to a one of them), speed limits, etc. They can also be managed by \emph{firewalls}. However the understanding of cloud networks and subnets is also different across providers.

For example let's describe the meaning of cloud networks and how they work in \textbf{IBM SoftLayer}. Each virtual server is given access to two default networks for the data center. It is a \emph{Private cloud network} and the \emph{Public cloud network}. They take place of a gate to different areas. The \emph{Private cloud network} connects the device to internal appliances within the data center. For instance such device can mean a network storage volumes or databases, etc. On the other hand the \emph{Public cloud network} is a gateway to the outer world, outside the data center and the cloud. To be precise the cloud networks in this sense does not offer any routing capabilities, they work just as a label of the range of interests available (reachable resources) for the device. And inside these networks \emph{cloud subnets} can be set up. Subnets here behave like the real networks or subnets. A customer can specify IP ranges and all other parameters he needs. The amount of subnets it the same network is not strictly limited for this cloud provider.

\subsubsection{Cloud router}
\label{subs:Cloud router}

A part from the attached devices and addresses each network needs its \emph{Network router}. This router is also not a physical device and for each subnetwork (as they are defined in the \textbf{IBM SoftLayer}) exist exactly one. Usually they are given a name and IP address and the only use for them is to build a proper illusion of the real network. Each router can service multiple subnets as it is known from the real world. Within each cloud network there can be multiple routers. However this architecture used in \textbf{IBM SoftLayer} does not provide more complex hierarchy, more levels of subnetworks. On contrary such advanced networking is not much common for cloud infrastructures currently deployed and this plain approach is sufficient enough.

\section{API access}
\label{sec:API access}

For managing purposes each cloud provider has it's own web interface. Such tool usually contains all needed functionality: visualization of leased devices and machines, networking adjustments, provisioning of new appliances, creating snapshots, viewing spendings and other billing information.

On the other hand once more advanced user wants to automate his work flows or create scripts to handle some of his common tasks an API is needed. There are numerous different libraries allowing a user to connect to the provider. In this case it is essential to focus on the \textbf{IBM SoftLayer} provider with respect to the needs and capabilities of \textbf{ManageIQ}.

\subsection{Standard REST API}
\label{sub:Standard REST API}

The standard way offered by the provider is to use the \textbf{IBM SoftLayer}'s \emph{REST API}~\cite{restapi}. This extensive API offers a complete access to all features of the cloud infrastructure. It is a low level standard defining how to communicate with the cloud, how to format requests and what responses should be expected etc. The major advantages of the API is in its complexity and independence on programming language.

\subsubsection{User authentication}
\label{subs:User authentication}

When user is managing the cloud services via web tool, the normal and most common way to identify himself is to use \emph{username} and \emph{password}. While using APIs the situation is a bit different. And each cloud define the way on their own. \textbf{Google Compute Engine} requires to specify the \emph{Project} name, user email and then use a special \emph{Google JSON key} which is basically a project specific certificate for the user. The \textbf{Amazon web services EC2} cloud use a generated pair of \emph{Access key ID} and a \emph{Secret Access key}. And when it comes to the \textbf{IBM SoftLayer} the factors used for authentication involves the normal \emph{User ID} and a specially generated \emph{Secret API key}.

\subsubsection{Language bindings}
\label{subs:Language bindings}

This API pretty simple and low level in the aspect of connection handling and abstract operations. For better integration of this API into user projects the derived libraries has been built upon it to offer bindings and object based interface for different programing languages. Since \textbf{ManageIQ} is written in \emph{Ruby} we should focus on and elaborate the libraries created for this programming language.

\subsection{Softlayer API for Ruby}
\label{sub:Softlayer-API}

First of them is a \emph{SoftLayer API} brought by the SoftLayer developers~\cite{softlayer_api}. This library provides a Ruby Gem packages named \texttt{softlayer\_api}. It offers a complex documentation and is designed for easy to use work flows. The code however is not much structured and organized.

\subsection{Fog the Ruby cloud service library}
\label{sub:Fog cloud library}

There's also a \texttt{fog-softlayer} gem, a \emph{Fog} library for this provider. \emph{Fog} is a cloud service library for Ruby available for many different providers across market. This makes the Gem easily understandable and compatible with other providers. It is also much simpler to maintain the structure and follow a pattern of other providers already available in the \textbf{ManageIQ} which are also implemented via \emph{Fog}. This library also offers extensive documentation (for \emph{Fog} in general) and example code for the \texttt{fog-softlayer} covering the desired functionality.

To compare the \texttt{fog-softlayer} with \texttt{softlayer\_api} the services and objects are more structured here. They are kept and managed via 5 basic services. These services can operate separately.

\begin{itemize}
	\item \texttt{Fog::Account} accessing customer account's organization if they are grouped with others
	\item \texttt{Fog::Compute} is the most important service allowing user to control servers (monitoring, provisioning, deployment, creating snapshots and more)
	\item \texttt{Fog::Network} offers bindings to manage cloud networks, subnets, routers, etc.
	\item \texttt{Fog::DNS} for managing DNS records
	\item \texttt{Fog::Storage} provides connection to \emph{Bluemix} storage service
\end{itemize}

Each of the services has its own purpose but the most important in a sense of cloud management is the \texttt{Fog::Compute} and \texttt{Fog::Network}. By using just these two user can easily manage his running appliances and deploy new ones. The code sample~\ref{code:fog_compute} shows the basic work flow for listing running servers and how to provision a new one.

\begin{lstlisting}[language=Ruby,caption={Example work flow for Fog SoftLayer},label=code:fog_compute,float=htpb]
require "fog/softlayer"

# Specify the provider and credentials
options = {
  :provider => "softlayer",
  :softlayer_username => "<username>",
  :softlayer_api_key  => "<api_key>"
}

# Connect to the Compute service
compute = ::Fog::Compute.new(options)

# lookup all provisioned servers
compute.servers.all

=>   <Fog::Compute::Softlayer::Servers
    [ <Fog::Compute::Softlayer::Server
        id=17784479,
        name="centos",
        domain="example.com",
        fqdn="centos.example.com",
        cpu=1,
        ram=1024,
        # etc.
      >,
			# other servers
    ]
  >

# get the first server and check its state
server = compute.servers.get(17784479)
server.state

=> 'Running'

# provision a new instance from image
provison_options = {
    :flavor_id => "m1.small",
    :image_id  => "1394bf94-e4e5-43bf-90ec-5eedbdcc420d",
    :name      => "ubuntu",
		:domain    => "example.com",
    :datacenter => "ams01"
}
new_instance = compute.servers.create(provision_options)
new_instance.id

=> 17784894
\end{lstlisting}

\chapter{ManageIQ}
\label{chap:ManageIQ}

A project named \textbf{ManageIQ} is an open-source technology developed by community supported and sponsored by the Red Hat company. This project aims to provide an easy management over cloud solutions across providers by offering comfortable import, appliances management, network links visualization allowing modifications and infrastructure provision capabilities. Expectations are high since all integrated technologies are different considered by functionality and capacity. To cover those variations \textbf{ManageIQ} brought some standardized API, covered functionality which should be offered for every such provided technology and integrated framework.

\section{Available interfaces}
\label{sec:Available interfaces}

\chapter{Implementation}
\label{chap:Implemented scheme}

As expected \textbf{ManageIQ} offers a namespace to bind the desired functionality.

\subsection{Cloud Manager}
\label{sub:Cloud Manager}



\subsection{Network Manager}
\label{sub:Network Manager}

In order to connect and visualize relations of discovered devices ManageIQ brings the class of network manager. \texttt{NetworkManager} In this case the class is declared as \texttt{ManageIQ::Providers::Softlayer::NetworkManager}.
